{
 "cells": [
  {
   "cell_type": "code",
   "id": "95ccbff402fa29e2",
   "metadata": {},
   "source": [
    "pip install py_clob_client"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f348a88c7e645e91",
   "metadata": {},
   "source": [
    "import os\n",
    "#from dotenv import load_dotenv\n",
    "import py_clob_client as clob\n",
    "from py_clob_client.client import ClobClient\n",
    "import urllib.parse\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccfb84e08a9ee5e6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8b8c78e29e8d068",
   "metadata": {},
   "source": [
    "gammaUrl = \"https://gamma-api.polymarket.com/markets\"\n",
    "host = 'https://clob.polymarket.com/'\n",
    "\n",
    "client = clob.client.ClobClient(host, chain_id=clob.constants.POLYGON)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1ce647d0bb63084",
   "metadata": {},
   "source": [
    "# Function to build the query string\n",
    "def build_query_string(base_url, params):\n",
    "    query_string = []\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, list):\n",
    "            for v in value:\n",
    "                query_string.append(f\"{key}={urllib.parse.quote(str(v))}\")\n",
    "        else:\n",
    "            query_string.append(f\"{key}={urllib.parse.quote(str(value))}\")\n",
    "\n",
    "    return base_url + \"?\" + \"&\".join(query_string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ffe2bfa4f5f439a5",
   "metadata": {},
   "source": [
    "# Get all Markets"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba41ab4c41a091a6",
   "metadata": {},
   "source": [
    "file_path = \"./markets_data.json\"\n",
    "all_results = []\n",
    "if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "    print(\"file exists\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_results = json.load(f)  # Load the JSON file into a Python list\n",
    "    print(len(all_results))\n",
    "else:\n",
    "    print(\"file doesn't exist\")\n",
    "    next_cursor = \"\"  # Start from the beginning\n",
    "    counter = 0\n",
    "    while next_cursor != \"LTE=\":\n",
    "        response = client.get_markets(next_cursor=next_cursor)\n",
    "        all_results.extend(response[\"data\"])  # Assuming data is inside \"data\" key\n",
    "        next_cursor = response.get(\"next_cursor\", \"LTE=\")  # Get the next cursor or default to \"LTE=\"\n",
    "        counter += len(response[\"data\"])\n",
    "        print(counter)\n",
    "        if next_cursor == \"LTE=\":\n",
    "            break  # Stop if we reach the end\n",
    "        time.sleep(0.1)  # Avoid rate limits\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1bbb9731db9f67f0",
   "metadata": {},
   "source": [
    "# Filter Markets"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c24305c19e7021c",
   "metadata": {},
   "source": [
    "all_markets = all_results.copy()\n",
    "\n",
    "#check for condition_id\n",
    "noConditionId = list(filter(lambda m: m.get(\"condition_id\") == \"\" or None, all_markets))\n",
    "print(f\"No ConditionId: {len(noConditionId)}\")\n",
    "\n",
    "print(f\"All markets: {len(all_markets)}\")\n",
    "\n",
    "all_markets = list(filter(lambda item: item[\"closed\"] == True, all_markets))\n",
    "print(f\"Closed: {len(all_markets)}\")\n",
    "\n",
    "all_markets = list(filter(lambda m: not any(t.get(\"token_id\") == \"\" for t in m.get(\"tokens\", [])), all_markets))\n",
    "print(f\"With existing tokens: {len(all_markets)}\")\n",
    "all_markets = list(filter(lambda m: len(m.get(\"tokens\", [])) == 2, all_markets))\n",
    "print(f\"With 2 tokens: {len(all_markets)}\")\n",
    "\n",
    "doubleTrue = list(filter(lambda m: all(t.get(\"winner\") == True for t in m.get(\"tokens\", [])), all_markets))\n",
    "print(f\"Both options true: {len(doubleTrue)}\")\n",
    "#print(json.dumps(doubleTrue))\n",
    "\n",
    "doubleFalse = list(filter(lambda m: all(t.get(\"winner\") == False for t in m.get(\"tokens\", [])), all_markets))\n",
    "print(f\"Both options false: {len(doubleFalse)}\")\n",
    "\n",
    "all_markets = list(filter(lambda m: sum(t.get(\"winner\") == True for t in m.get(\"tokens\", [])) == 1, all_markets))\n",
    "print(f\"With one winner: {len(all_markets)}\")\n",
    "\n",
    "all_markets = list(filter(lambda m: sum(t.get(\"winner\") == False for t in m.get(\"tokens\", [])) == 1, all_markets))\n",
    "print(f\"With one loser: {len(all_markets)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming your list of markets is called all_markets\n",
    "first_outcomes = [market[\"tokens\"][0][\"outcome\"] for market in all_markets if market.get(\"tokens\")]\n",
    "\n",
    "# Count how many times each outcome appears\n",
    "counts = Counter(first_outcomes)\n",
    "\n",
    "# Print nicely\n",
    "for outcome, count in counts.items():\n",
    "    print(f\"{outcome}: {count}\")"
   ],
   "id": "22d8003c7f53e6eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36219366c2c9bb6a",
   "metadata": {},
   "source": [
    "# Get Prices"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "def GetHistoricalPrice(tokenId):\n",
    "    fidelity = 10  # Start with default 10-minute fidelity\n",
    "\n",
    "    params = {\n",
    "        \"market\": tokenId, #number, the CLOB token id for which to fetch price history\n",
    "        \"startTs\": 1, #number \tthe start time, a unix timestamp in UTC\n",
    "        \"fidelity\": fidelity, #number \tthe resolution of the data, in minutes\n",
    "    }\n",
    "\n",
    "    final_url = build_query_string(host + \"/prices-history\", params)\n",
    "    httpRes = clob.http_helpers.helpers.get(final_url)\n",
    "    time.sleep(0.205)  # Respect rate limits\n",
    "    history = httpRes[\"history\"]\n",
    "\n",
    "    if not history:\n",
    "        return []\n",
    "\n",
    "    if len(history) >= 100:\n",
    "        return history\n",
    "    timestamps = [point[\"t\"] for point in history]\n",
    "    timespan = max(timestamps) - min(timestamps)\n",
    "\n",
    "    # Convert timespan from seconds to minutes for fidelity calculation\n",
    "    timespan_minutes = timespan / 60\n",
    "    ideal_fidelity = max(int(timespan_minutes / 100), 1)\n",
    "    #print(f\"{len(history)} prices, try with {ideal_fidelity} on token {tokenId}\")\n",
    "    params[\"fidelity\"] = ideal_fidelity\n",
    "\n",
    "    final_url = build_query_string(host + \"/prices-history\", params)\n",
    "    httpRes = clob.http_helpers.helpers.get(final_url)\n",
    "    time.sleep(0.205)  # Respect rate limits\n",
    "    history = httpRes[\"history\"]\n",
    "\n",
    "    return history"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b613035805b29d54",
   "metadata": {},
   "source": [
    "def resample(prices):\n",
    "    # sort ascending for timestamp\n",
    "    pricesSorted = sorted(prices, key=lambda p: p[\"t\"])\n",
    "\n",
    "    # Convert to arrays\n",
    "    timestamps = np.array([p[\"t\"] for p in pricesSorted])\n",
    "    price_values = np.array([p[\"p\"] for p in pricesSorted])\n",
    "\n",
    "    # 100 evenly spaced timestamps between first and last\n",
    "    even_timestamps = np.linspace(timestamps[0], timestamps[-1], 100)\n",
    "\n",
    "    # Find closest previous price for each timestamp\n",
    "    indices = np.searchsorted(timestamps, even_timestamps, side='right') - 1\n",
    "    indices = np.clip(indices, 0, len(pricesSorted) - 1)\n",
    "\n",
    "    resampled = price_values[indices]\n",
    "    return resampled"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49a467713554f265",
   "metadata": {},
   "source": [
    "existing_condition_ids = set()\n",
    "\n",
    "filename = \"processed_markets.csv\"\n",
    "if not os.path.exists(filename):\n",
    "    open(filename, 'w').close()\n",
    "\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        existing_condition_ids.add(row['condition_id'])\n",
    "\n",
    "print(f\"existing: {len(existing_condition_ids)}\")\n",
    "noPriceFoundMarkets = []\n",
    "invalidPricesFoundMarkets = []\n",
    "writtenToFile = 0\n",
    "pricesLength = []\n",
    "\n",
    "with open(filename, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\n",
    "        \"condition_id\", \"market_slug\", \"tags\", \"start\", \"end\", \"yes_token_id\", \"winner_token\",\n",
    "        *[f\"price_{i}\" for i in range(100)]\n",
    "    ]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Only write the header if the file is empty\n",
    "    csvfile.seek(0, 2)\n",
    "    if csvfile.tell() == 0:\n",
    "        writer.writeheader()\n",
    "\n",
    "    with tqdm(total=len(all_markets), desc=\"Processing markets\", initial=len(existing_condition_ids)) as progress_bar:\n",
    "        for market_data in all_markets:\n",
    "            condition_id = str(market_data[\"condition_id\"])  # Convert to string for comparison\n",
    "\n",
    "            # Skip if condition_id already exists in the CSV\n",
    "            if condition_id in existing_condition_ids:\n",
    "                continue\n",
    "\n",
    "            tokens = market_data[\"tokens\"]\n",
    "\n",
    "            yes_token_id = tokens[0][\"token_id\"]\n",
    "            winner_token = tokens[0][\"winner\"]\n",
    "            market_slug = market_data[\"market_slug\"]\n",
    "            tags = str(market_data.get(\"tags\", []) or [])\n",
    "\n",
    "            price_history = GetHistoricalPrice(yes_token_id)\n",
    "            if not price_history:\n",
    "                noPriceFoundMarkets.append(market_data)\n",
    "                progress_bar.update(1)\n",
    "                #print(f\"No historical prices found for market with conditionId {condition_id}, slug {market_slug}.\")\n",
    "                continue\n",
    "\n",
    "            resampled_prices = resample(price_history)\n",
    "\n",
    "            if any(price < 0 or price > 1 for price in resampled_prices):\n",
    "                invalidPricesFoundMarkets.append(market_data)\n",
    "                progress_bar.update(1)\n",
    "                continue\n",
    "\n",
    "            pricesLength.append(len(price_history))\n",
    "\n",
    "            timestamps = [entry[\"t\"] for entry in price_history]\n",
    "            lowest_timestamp = min(timestamps)\n",
    "            highest_timestamp = max(timestamps)\n",
    "\n",
    "            # Prepare market data to write to CSV\n",
    "            processed_market = {\n",
    "                \"condition_id\": condition_id,\n",
    "                \"market_slug\": market_slug,\n",
    "                \"tags\": tags,\n",
    "                \"start\": lowest_timestamp,\n",
    "                \"end\": highest_timestamp,\n",
    "                \"yes_token_id\": yes_token_id,\n",
    "                \"winner_token\": winner_token,\n",
    "            }\n",
    "\n",
    "            # Add 100 price columns: price_0, price_1, ..., price_99\n",
    "            for i, price in enumerate(resampled_prices):\n",
    "                processed_market[f\"price_{i}\"] = price\n",
    "\n",
    "            # Write the processed market row to the CSV file\n",
    "            writer.writerow(processed_market)\n",
    "            writtenToFile += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.update(1)\n",
    "print(f\"Wrote {writtenToFile} markets to file\")\n",
    "print(f\"Markets with no prices: {len(noPriceFoundMarkets)}\")\n",
    "print(f\"Markets with invalid prices: {len(invalidPricesFoundMarkets)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the histogram\n",
    "plt.hist(pricesLength, bins='auto', edgecolor='black')  # 'auto' lets matplotlib determine the optimal number of bins\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Length of Price Lists')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Price List Lengths')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "c668ac374f3c04e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
